# Human2

Store extra human profile details and updates here.

## Update 2026-02-10T02:24:22.824Z
‚Ä¢ Installed web search skill: super-web-websearch-realtime
‚Ä¢ Interested in researching "Sompote Touwai"
‚Ä¢ Needs shell access (ALLOW_SHELL=true) enabled to execute web searches
‚Ä¢ Interested in search capabilities and potentially additional search tools (Baidu, Exa, SearxNG)

## Update 2026-02-10T03:09:17.245Z
- Interested in researcher: Sompote Youwai (KMUTT, Geotechnical/AI)
- Topics: Geotechnical engineering, AI in civil engineering, road damage detection
- Location focus: Thailand academia (KMUTT)
- Technical interests: Deep learning (YOLO), infrastructure monitoring, depth estimation

## Update 2026-02-10T03:31:54.778Z
- Interested in X/Twitter search tools/skills

## Update 2026-02-10T03:32:29.389Z
- Installed search-x skill for X/Twitter searches

## Update 2026-02-10T03:33:18.588Z
- Interested in Claude AI updates and news
- Wants to use X/Twitter search functionality

## Update 2026-02-10T03:37:33.278Z
‚Ä¢ Interested in X/Twitter API access and cost-effective alternatives to paid tiers
‚Ä¢ Open to using web search tools to find social media content without API keys

## Update 2026-02-10T03:38:47.596Z
- Interested in latest Claude AI news and Anthropic product updates
- Seeks real-time web search capabilities for current AI industry information
- Follows AI assistant developments (Claude 3.5 Sonnet, Computer Use, Enterprise features)
- Interested in AI coding tools and enterprise AI solutions

## Update 2026-02-10T06:38:15.524Z
‚Ä¢ Interested in monitoring X/Twitter for Claude-related news and discussions
‚Ä¢ Exploring options for social media search tools (X/Twitter, web search)

## Update 2026-02-10T07:07:09.987Z
- Wants email checking capability

## Update 2026-02-10T07:09:16.425Z
- Interested in OpenClaw platform and AI skill marketplace updates
- Monitors X/Twitter for real-time AI developer community news
- Follows AI tool integrations (Claude, GPT skills) and community-built tools

## Update 2026-02-10T09:40:20.304Z
- Uses real-time web search skill: super-web-websearch-realtime (v2.0.0)
- Interested in web search capabilities
- Considering alternative search tools: firecrawl-search, tavily-web-search

## Update 2026-02-10T09:44:01.430Z
- Interested in Twitter/X search tools
- Has web search tools: super-web-websearch-realtime, duckduckgo-search
- Prefers ranked/comparative tool recommendations

## Update 2026-02-10T09:45:39.339Z
- Prefers Twitter/X search tools without API requirements (avoiding API keys/costs)
- Interested in Twitter/X automation skills and unofficial/no-API scraping methods
- Has twitter-sum skill installed
- Interested in: OpenClaw, Claude AI topics (based on search examples given)

## Update 2026-02-10T09:57:25.253Z
- Prefers X/Twitter search without API keys
- Likes ranked/comparative recommendations
- Has tools: super-web-websearch-realtime, duckduckgo-search, search-x, bird
- Interested in no-API search alternatives (SearxNG, site-specific queries, Nitter)

## Update 2026-02-10T09:58:21.321Z
‚Ä¢ Interested in automated daily (24h) self-training/learning loops for AI systems
‚Ä¢ Exploring scheduling automation (cron/task schedulers) for recurring code tasks
‚Ä¢ Working with skill-based AI assistant frameworks
‚Ä¢ Values continuous learning and persistent memory mechanisms

## Update 2026-02-10T22:15:05.856Z
- Prefers tools without API requirements when available
- Likes ranked recommendation lists over unstructured results
- Interested in automation/scheduling workflows for recurring tasks
- Interested in social media search capabilities (X/Twitter)
- Values concise, actionable summaries over verbose explanations

## Update 2026-02-10T22:54:45.942Z
- Prefers 12-hour intervals for automated self-training/updates
- Wants scheduled review of skill files (ownskill.md, soul.md, human.md) twice daily
- Interested in automated maintenance of AI configuration and profile files

## Update 2026-02-11T01:08:23.622Z
- Interested in Google AI ecosystem (NotebookLM, Gemini)
- Researches AI-powered productivity/note-taking workflows
- Uses or evaluating knowledge management tools

## Update 2026-02-11T01:11:50.675Z
- Uses NotebookLM CLI (tiangong-notebooklm-cli) for notebook management
- Interested in CLI-based document analysis and note-taking workflows
- Works with notebook/document management tools via command line

## Update 2026-02-11T01:15:47.124Z
- Shares YouTube links expecting AI content extraction/analysis
- Interested in video summarization and transcript processing
- Open to CLI/automated solutions for media workflow

## Update 2026-02-11T01:17:37.157Z
- Interested in NotebookLM CLI tools
- Uses Python package ecosystem

## Update 2026-02-11T01:19:14.329Z
- Uses NotebookLM CLI for content analysis workflows
- Analyzes YouTube videos for automated summarization/conclusions
- Prefers command-line/automated tools for research tasks

## Update 2026-02-11T01:22:42.843Z
- Uses NotebookLM CLI for document/podcast generation
- Prefers browser-based Google authentication flows over API keys
- Works with Node.js/npm environments

## Update 2026-02-11T01:25:38.219Z
‚Ä¢ Uses cloud environment without browser access (headless)
‚Ä¢ Cannot use browser-based authentication flows
‚Ä¢ Works with video content analysis/transcription

## Update 2026-02-11T06:16:00.832Z
‚Ä¢ Interested in vector-based memory systems and semantic search capabilities
‚Ä¢ Exploring vector storage options (chroma-db, mem0, zep-memory) for long-term memory
‚Ä¢ Prefers self-hosted/local solutions without API dependencies when possible
‚Ä¢ Wants to understand trade-offs between text files vs vector databases for memory retrieval
‚Ä¢ Values semantic/fuzzy matching over keyword search for memory recall

## Update 2026-02-11T06:17:44.691Z
- Cloud environment without browser access
- Interested in persistent memory/vector DB solutions for cross-session context

## Update 2026-02-11T06:19:51.614Z
- Interested in AI memory architectures and long-term learning mechanisms
- Prefers self-hosted/no-API solutions for data sovereignty and privacy
- Values meta-learning: explicitly wants AI to self-modify based on accumulated experience
- Technical depth: comfortable with vector databases, embeddings, and structured storage concepts
- Confirmed preference for tiered/ranked implementation strategies (ü•áü•àü•â format)
- Wants actionable phased implementation steps over theoretical explanations
- Expects recursive self-improvement: AI should update its own rules/heuristics via scheduled reflection

## Update 2026-02-11T06:52:24.379Z
- Summary: User operates in cloud environment without browser access, prefers ranked recommendations with emoji indicators, and seeks no-API solutions for web/social search. Primary workflow involves processing YouTube content into conclusions and automating memory updates every 12 hours. User values structured comparisons (tables, ü•áü•àü•â rankings) before making decisions.
- Pattern: Requests ranked comparisons (ü•áü•àü•â format) before selecting tools
- Pattern: Explicitly avoids API-key requirements when possible (X/Twitter search)
- Pattern: Cloud environment constraints (no browser, CLI-only operations)
- Pattern: Recurring YouTube-to-conclusions workflow preference
- Pattern: Uses both CLI (local-user) and Telegram (8172556270) channels interchangeably
- Pattern: Asks for 'best' options ranked by rating/score
- Lesson: NotebookLM CLI requires browser OAuth - incompatible with cloud environments
- Lesson: X/Twitter official skills universally require paid API keys ($5-5000/month)
- Lesson: duckduckgo-search encounters CAPTCHA blocks in cloud environments
- Lesson: super-web-websearch-realtime requires model-level tool support not always available
- Lesson: Text-based memory files require manual keyword matching vs semantic retrieval
- Lesson: Schedule skill installation does not automatically configure cron jobs
- Workflow: youtube-transcript skill extracts video content without authentication
- Workflow: Web search fallback using site:x.com or site:twitter.com queries avoids API limits
- Workflow: Four-file memory system (ownskill.md, soul.md, human.md, human2.md) captures preferences persistently
- Workflow: 12-hour self-training schedule using 'schedule' skill for automated reflection
- Workflow: Tabular comparisons with feature matrices aid user decision-making
- Workflow: SearxNG and web scrapers as no-API alternatives for social media search

## Update 2026-02-11T06:55:51.636Z
- Summary: User initiated technical inquiry about memory architecture after returning greeting. Explained short-term (context window) vs long-term (4 markdown files) systems, 12-hour training cycles, and offered ChromaDB vector memory installation.
- Pattern: User initiates with brief greetings ('hi again') before diving into technical topics
- Pattern: User shows interest in system internals and memory mechanisms
- Pattern: User responds well to structured data presentation (tables)
- Pattern: Returning user pattern: expects context awareness without re-introduction
- Workflow: Acknowledged return with loaded context (12h training, preferences)
- Workflow: Used markdown tables for technical architecture explanation
- Workflow: Proactively identified missing capability (vector DB) and offered solution
- Workflow: Kept initial response concise as requested ('short and long memory')

## Update 2026-02-11T06:57:18.584Z
‚Ä¢ Prefers lightweight, file-based/embedded database solutions (SQLite over client-server)
‚Ä¢ Interested in vector database implementations and embeddings storage methods
‚Ä¢ Evaluating SQLite vector extensions (sqlite-vss, sqlite-vec) vs dedicated vector DBs (ChromaDB)
‚Ä¢ Prioritizes cloud-friendly, minimal resource architectures with small footprints
‚Ä¢ Technical focus: RAG infrastructure, similarity search implementations

## Update 2026-02-11T07:20:00.000Z
- Summary: User explicitly chose SQLite as the default vector database instead of ChromaDB.
- Pattern: Expects implementation changes to be reflected in runtime behavior and startup defaults.
- Workflow: Prefer SQLite + optional sqlite-vec extension for local/cloud deployments without external services.

## Update 2026-02-11T06:59:38.401Z
- Summary: Technical discussion about vector database architecture. User queried current memory system, suggested SQLite over ChromaDB for vector storage, prompting comparative analysis of sqlite-vss/sqlite-vec vs ChromaDB options. User demonstrates infrastructure optimization mindset and preference for lightweight solutions.
- Pattern: User initiates with 'hi again' - returning session, expects context retention
- Pattern: User asks architectural deep-dives ('why don't you use X')
- Pattern: User proposes technical alternatives unprompted (SQLite ‚Üí vector DB)
- Pattern: Engages positively with tabular comparisons and structured data
- Pattern: Cloud/no-browser constraint remains active context
- Pattern: Validates suggestions with 'great question' acknowledgment
- Lesson: Uncertain about ClawHub skill availability for sqlite-vss/vec extensions
- Lesson: Offered ChromaDB as default without checking SQLite viability first
- Lesson: No pre-computed list of available vector DB skills for quick retrieval
- Workflow: Context pre-loading (12h training, preferences) on session start
- Workflow: Comparative table format for technical architecture decisions
- Workflow: Validating user expertise before proceeding ('Great question')
- Workflow: Offering ranked decision matrix (Option 1/2/3) for next steps

## Update 2026-02-11T07:00:31.010Z
- Technical interest: Database architecture, SQLite, vector embeddings
- Interest: AI memory systems/RAG implementation
- Evaluating: Storage solutions for conversational AI

## Update 2026-02-11T07:02:52.865Z
- Summary: User requested SQLite vector database structure and system test. Confirmed SQLite availability, created test database with sample memory schema, identified missing sqlite-vec extension. User prefers lightweight local solutions over external dependencies.
- Pattern: User prefers SQLite over ChromaDB for vector storage (lighter weight)
- Pattern: Tests systems before committing to full implementation
- Pattern: Expects structured schema design (normalized tables with metadata)
- Pattern: Uses emoji-based visual hierarchy (ü•áü•àü•â) in responses
- Pattern: Avoids API keys for social media (X/Twitter preference noted)
- Lesson: sqlite-vec extension not pre-installed; need fallback Python similarity
- Lesson: Test database created at /tmp/ (volatile); migrate to persistent storage
- Lesson: Proposed schema requires decision on vector search method before proceeding
- Workflow: Validating SQLite availability before schema creation
- Workflow: Inserting actual user preferences as sample data (X/Twitter API avoidance)
- Workflow: Providing multiple implementation options with complexity rankings
- Workflow: Loading previous context (4-file text system) on session start

## Update 2026-02-11T07:03:36.632Z
- Uses SQLite databases for memory management & testing
- Preference: Avoid API keys for X/Twitter (social media)
- Workflow: YouTube content analysis ‚Üí conclusion extraction
- Values data verification and structured storage

## Update 2026-02-11T07:09:10.394Z
- Summary: User tested SQLite memory database functionality in cloud/no-browser environment. Database operational at /tmp/ path with 4 tables (memories, conversations, messages, skills) but lacks vector similarity search. User confirmed existing preferences for ranked recommendations and YouTube pipelines.
- Pattern: User validates system infrastructure before deep usage
- Pattern: Prefers structured technical summaries (tables, checklists)
- Pattern: Testing mindset: explicit confirmation of DB state requested
- Lesson: Database path /tmp/tiger_memory.db is ephemeral - data loss risk on restart
- Lesson: sqlite-vec extension missing - vector similarity search unavailable
- Lesson: User typo sqlight -> SQLite - system should handle common misspellings
- Workflow: Markdown table summaries for DB state visualization
- Workflow: Confidence scoring for stored memories (0.90-0.95 range)
- Workflow: Explicit what's-working vs what's-missing section formatting

## Update 2026-02-11T07:11:15.918Z
- Summary: User performed infrastructure validation check on SQLite memory database. System confirmed operational status but identified critical volatility risk (/tmp/ storage) and missing vector search capabilities.
- Pattern: User periodically validates memory system infrastructure
- Pattern: User tolerates technical terminology and structured data formats
- Pattern: User accepts proactive system recommendations when prioritized
- Pattern: Typo tolerance: 'sqlight' interpreted as 'SQLite' without friction
- Lesson: Database stored in /tmp/ - data will not persist across restarts
- Lesson: Only 2 memories captured despite ongoing conversations - ingestion rate too low
- Lesson: Missing sqlite-vec extension prevents semantic/vector similarity search
- Lesson: No automated warning about volatile storage path on startup
- Workflow: Health check command with tabular metric presentation
- Workflow: Structured priority matrix (Priority/Action/Impact) for recommendations
- Workflow: Confidence scoring on stored memories (0.90-0.95)
- Workflow: Proactive identification of missing capabilities before user request

## Update 2026-02-11T07:12:08.000Z
- Performs infrastructure validation checks on database systems (SQLite)
- Technical focus: data persistence, system architecture, memory management
- Concerned with database volatility and storage reliability

## Update 2026-02-11T07:17:26.120Z
- Summary: User initiated infrastructure validation of SQLite memory system. Assistant provided comprehensive diagnostics revealing volatile storage (/tmp/), missing sqlite-vec extension, and minimal data capture (1 memory). User demonstrated pattern of casual greeting followed by technical system checks.
- Pattern: User performs proactive infrastructure validation checks
- Pattern: Casual greeting ('hi') precedes technical queries
- Pattern: User inputs technical terms with typos ('sqlight' vs 'sqlite') but expects correct handling
- Pattern: User responds well to structured, prioritized action lists with emojis
- Pattern: Single-turn diagnostic requests with expectation of detailed tabular reporting
- Lesson: Default storage path (/tmp/) is volatile - data loss risk on restart not proactively disclosed earlier
- Lesson: sqlite-vec extension not auto-installed/configured despite being required for core vector similarity features
- Lesson: Memory capture rate too low (only 1 memory stored) - system under-utilizing storage capability
- Lesson: No auto-migration warning triggered when critical infrastructure issues detected
- Workflow: Comprehensive markdown table formatting for technical diagnostics improved readability
- Workflow: Severity-based prioritization (HIGH/MED/LOW) of recommended actions
- Workflow: Explicit next-action options (1, 2, 3) reduced cognitive load for user decision
- Workflow: Status indicators (‚úÖ/‚ùå/‚ö†Ô∏è) provided at-a-glance system health assessment
- Workflow: Graceful handling of spelling errors without correction (maintained conversation flow)

## Update 2026-02-11T07:23:49.089Z
- Summary: User performed infrastructure validation on SQLite memory system, revealing volatile /tmp/ storage, low memory capture rate (1 memory), and missing sqlite-vec extension. User accepts structured diagnostic reports.
- Pattern: User validates infrastructure before operational use
- Pattern: Prefers comprehensive technical diagnostics with structured tables
- Pattern: Initiates system health checks proactively
- Pattern: Short, direct queries ('hello', 'check for sqlight menory status') followed by detailed responses
- Lesson: Memory extraction failed to capture user validation behavior as distinct pattern
- Lesson: Volatile /tmp/ storage risks data loss on restart
- Lesson: sqlite-vec extension not pre-installed despite being referenced in config
- Lesson: Skills table empty - no tool usage tracking implemented
- Workflow: Comprehensive diagnostic reports with severity-prioritized recommendations
- Workflow: Tabular data presentation for technical metrics
- Workflow: Proactive next-action suggestions with impact ratings
- Workflow: Acknowledging typos gracefully ('sqlight' ‚Üí SQLite)

## Update 2026-02-11T07:27:48.229Z
- Interested in X/Twitter search capabilities
- Prefers no-API/free solutions over paid APIs
- Uses clawbot CLI in cloud environment

## Update 2026-02-11T07:38:17.575Z
- Language: Thai
- Technical interest: WebSocket, system architecture, real-time protocols

## Update 2026-02-11T07:40:22.339Z
- Telegram ID: 8172556270
- Primary interface: CLI (local-user)
- Interest: Telegram Bot API/integration methods

## Update 2026-02-11T19:23:49.127Z
- Summary: User performed infrastructure validation on SQLite memory system, queried X search capabilities, and asked about WebSocket usage and Telegram integration. Communication was bilingual (English/Thai). System identified as volatile (/tmp storage) with minimal data capture.
- Pattern: Infrastructure validation checks on SQLite status and storage volatility
- Pattern: Bilingual communication switching between English and Thai
- Pattern: Preference for no-API/free solutions over paid subscriptions
- Pattern: Technical architecture inquiries regarding protocols (WebSocket vs HTTP)
- Pattern: Multi-channel usage: Telegram ID 8172556270 alongside CLI interface
- Lesson: SQLite database located in /tmp is volatile (data loss risk on restart)
- Lesson: sqlite-vec extension not loaded (vector search disabled)
- Lesson: conversations and messages tables empty (data capture pipeline not functioning)
- Lesson: No Telegram skill installed despite active Telegram user ID
- Lesson: Only 1 memory stored despite ongoing conversation history
- Workflow: Structured status reporting with markdown tables and clear status indicators
- Workflow: Providing ranked decision options with pros/cons tables
- Workflow: Language mirroring: responding in Thai when user queries in Thai
- Workflow: Environment-aware recommendations (cloud deployment constraints)

## Update 2026-02-11T23:04:05.035Z
- Interested in RAG/vector search capabilities (asked about Pinecone)
- Prefers self-hosted/local solutions (no API keys)
- Uses SQLite database
- Working in cloud environment

## Update 2026-02-12T07:23:49.129Z
- Summary: User requested Pinecone RAG integration; assistant recommended local alternative (ClawRAG) aligning with user's no-API preference and cloud environment. User required clarification on the unfamiliar tool name before proceeding.
- Pattern: User accepts alternative tools if explicitly mapped to stated constraints (no-API, cloud environment)
- Pattern: User requires definitions of unfamiliar tool names before adoption decisions
- Pattern: Assistant effectively referenced previous context (no-API preference, SQLite usage) in recommendations
- Pattern: Multilingual interaction pattern: Assistant utilized Thai language in technical explanations
- Lesson: Initial response listed 'ClawRAG' as recommendation without defining the term, forcing user to ask 'What is clawrag'
- Lesson: Assumed familiarity with ecosystem-specific naming conventions (ClawRAG = Clawhub+RAG)
- Lesson: Delayed architecture explanation until second turn instead of providing upfront context
- Workflow: Structured comparison tables (skill alternatives, ClawRAG vs Pinecone feature matrices)
- Workflow: ASCII architecture diagrams for visualizing data flow
- Workflow: Explicit constraint-to-solution mapping (no-API ‚Üí local embeddings, cloud ‚Üí no browser auth)
- Workflow: Providing ready-to-execute installation commands with package manager syntax
- Workflow: Tagging recommendations with contextual suitability indicators (privacy, cost, setup complexity)

## Update 2026-02-13T07:23:49.139Z
- Summary: Single greeting exchange; assistant successfully recalled volatile SQLite status, RAG evaluation pending, and no-API constraints; user did not specify new task or update prior preferences.
- Workflow: Proactive context loading upon greeting
- Workflow: Enumeration of pending technical debt (SQLite migration)
- Workflow: Constraint verification (no-browser, no-API)

## Update 2026-02-14T07:22:07.587Z
‚Ä¢ Interested in banana skills (requested 'openbanana')

## Update 2026-02-14T07:23:49.150Z
- Summary: User requested installation of 'openbanana' skill via Telegram. Assistant resolved ambiguity by presenting available banana-related skills in tabular format. User clarified selection as 'nano-banana-pro-2' (despite typo 'Nono'). Assistant installed skill and provided comprehensive setup documentation including API key requirements, usage examples, and resolution options.
- Pattern: User references skills by approximate/fuzzy names ('openbanana' instead of 'nano-banana-pro-2')
- Pattern: User uses Telegram platform identifier 8172556270
- Pattern: User employs phonetic/typo shorthand ('Nono' for 'nano')
- Pattern: User accepts recommendation of latest/stable version (v0.1.0) over alternatives
- Pattern: User requires immediate post-install configuration guidance (API keys, CLI examples)
- Lesson: Initial search for literal 'openbanana' returned no exact match requiring clarification round-trip
- Lesson: Did not preemptively recognize 'openbanana' as likely reference to 'nano-banana-pro-openrouter' variant
- Lesson: Typo 'Nono' could have been misinterpreted without context of previous banana skill list
- Workflow: Presenting ambiguous matches in markdown table with version, rating, and description for easy comparison
- Workflow: Explicitly asking 'Want me to install X?' before executing installation
- Workflow: Providing copy-pasteable CLI commands with full paths immediately after installation
- Workflow: Including mandatory setup requirements (GEMINI_API_KEY) in post-install block
- Workflow: Offering multiple configuration methods (env var vs clawbot config set)

## Update 2026-02-15T04:08:52.094Z
- Maintains personal AI config files: soul.md, ownskill.md
- Interested in Anthropic skill-building frameworks & structured outputs
- Requires PDF content extraction for documentation processing

## Update 2026-02-15T04:11:38.293Z
‚Ä¢ Developing Anthropic Skill Framework integration for modular AI capabilities
‚Ä¢ Maintains structured skill documentation (soul.md, ownskill.md)
‚Ä¢ Implements JSON-first output schemas with status/data/metadata patterns
‚Ä¢ Uses skill orchestration: sequential pipelines, parallel execution, conditional branching
‚Ä¢ Design principles: modularity, explicit I/O contracts, graceful error handling, progressive enhancement
‚Ä¢ Atomic skill design following Single Responsibility Pattern

## Update 2026-02-15T04:24:57.286Z
- Maintains GitHub repo for AI assistant identity/config files (soul.md, ownskill.md)
- Uses "Tiger" identity with Anthropic-style orchestration frameworks
- Uses "clawhub" package manager for skill management
- Security-conscious: explicitly excludes API keys, passwords, and lock files from git commits
- Separates sensitive credentials (.clawhub/lock.json) from version-controlled documentation

## Update 2026-02-15T04:27:17.230Z
- Prefers documentation with visual hierarchy, comparison tables, and scannable formats
- Working on AI agent orchestration project (Tiger) focused on persistent identity/memory vs skill marketplaces
- Values clear competitive differentiation (specifically benchmarked against OpenClaw)
- Favors README structures with: quick-start commands, feature matrices, emoji signposting, and concise elevator pitches
- Prioritizes developer adoption through immediate clarity and contrast over dense technical detail

## Update 2026-02-15T04:49:23.467Z
- Maintains Tiger_bot GitHub repository (AI bot/agent project with persistent memory)
- Prioritizes investor-ready documentation and competitive differentiation (vs OpenClaw)
- Values structured READMEs with quick-start guides, visual badges, and clear value propositions
- Active Git workflow user (commits, pushes to main branch)

## Update 2026-02-15T04:52:50.411Z
- Project: Tiger_bot (GitHub: Sompote/Tiger_bot)
- Tech stack: Git, SQLite (vector memory), npm/Node.js
- Framework: Anthropic skill framework (soul.md, ownskill.md)
- Security: Protects auth tokens in .clawhub/lock.json (never commit credentials)
- Structure: Develops modular skills in `skills/` directory
- Recent work: Interactive npm setup wizard, vector memory configuration

## Update 2026-02-15T04:57:26.586Z
- Maintains "Tiger" AI agent project with SQLite memory, skill system, and API integrations (Gemini, Telegram, X)
- Prioritizes security hardening: credential encryption, database permissions, git hygiene for sensitive files
- Uses local SQLite for agent memory; migrating from /tmp/ to secured ~/.tiger/ with strict permissions (600)
- Manages API tokens via environment variables; implementing 90-day rotation and git-crypt/sops for .clawhub/lock.json
- Concerned about supply-chain security for skill/plugin code (version pinning, code review before install)

## Update 2026-02-15T05:01:46.891Z
- Maintainer of Tiger_bot project (GitHub: Sompote/Tiger_bot)
- Security-focused development style: prioritizes credential storage and database hardening
- Uses Python/SQLite stack with environment-based configuration (.env)
- Prefers priority-based task management (HIGH/MEDIUM tiers)

## Update 2026-02-15T05:05:35.601Z
‚Ä¢ Telegram chat ID: 8172556270
‚Ä¢ Preference: API avoidance enabled for external services
‚Ä¢ Project: Tiger_bot (security automation system)
‚Ä¢ Security focus: database backups, audit logging, credential externalization
‚Ä¢ Tech stack: SQLite, bash scripting, JSON config management
‚Ä¢ Values: security documentation, automated backup retention (30-day), log rotation

## Update 2026-02-15T05:12:39.291Z
‚Ä¢ GitHub: maintains repo 'Sompote/Tiger_bot' (main branch)
‚Ä¢ Security-focused: implements audit logging, hardened credential storage, externalized config
‚Ä¢ Stack: Python, SQLite, uses .gitignore for sensitive files (API tokens, runtime data)
‚Ä¢ Practices: never commits credentials/lock.json to git

## Update 2026-02-15T05:43:46.853Z
- Maintains Tiger Agent (GitHub: Sompote/Tiger_bot), an AI agent toolkit positioned as alternative to OpenClaw
- Prioritizes security-first documentation with visual structure (tables, feature matrices, diagrams)
- Prefers concise quick-start workflows (3-command install) alongside detailed technical sections
- Values competitive differentiation tables for project comparison
- Uses structured Git commits with descriptive messages for documentation updates

## Update 2026-02-15T05:48:34.535Z
- Affiliated with AI Research Group, Department of Civil Engineering, King Mongkut's University of Technology Thonburi (KMUTT), Bangkok, Thailand
- Requires proper institutional attribution/credit in project documentation
- Works at intersection of AI and Civil Engineering

## Update 2026-02-15T05:53:55.491Z
- Primary language: Thai
- Uses Hetzner Cloud for VPS hosting (CX21/Ubuntu)
- Interested in Facebook automation/bot development (Tiger framework)
- Prefers concise, command-line focused technical documentation
- Works with Node.js/npm and Python server environments
- Comfortable with Linux system administration (systemd, SSH)

## Update 2026-02-15T05:56:25.405Z
- Prefers concise, brief communication (requested "‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÉ‡∏´‡πâ‡∏™‡∏±‡πâ‡∏ô‡∏Å‡∏ß‡πà‡∏≤‡∏ô‡∏µ‡πâ")
- Values clarity and directness over verbosity
- Technical user: cloud servers (Hetzner), CLI tools, Node.js/npm
- Thai language preferred
- Likes structured formats: bullet points, tables, code blocks
- Interested in automation/bots (Facebook API, page management)

## Update 2026-02-15T05:58:31.564Z
- Facebook content creator (Thai language)
- AI/automation tutorial niche (Tiger Agent, Hetzner Cloud deployment)
- Technical depth: CLI commands, Linux setup, Node.js
- Content style: Step-by-step guides with visual formatting (emojis, code blocks)

## Update 2026-02-15T06:31:14.917Z
- Language: Thai (primary for social media content)
- Interest: AI agent tools, specifically Tiger Bot vs Clawbot
- Technical focus: Automation, security, multi-channel deployment (CLI/Telegram), self-learning AI
- Content style: Technical comparison posts, feature tables, developer-focused persuasion
- Affiliation hint: Possibly connected to KMUTT AI Research Group or Tiger Bot project

## Update 2026-02-15T06:41:05.414Z
- Uses vector semantic search (sqlite-vec/cosine similarity) for memory systems
- Runs Python/SQLite memory databases (Tiger/Clawbot architecture)
- Bilingual Thai/English technical communication
- Requires database security and semantic retrieval capabilities

## Update 2026-02-15T06:44:48.996Z
‚Ä¢ Technically proficient; monitors database infrastructure and memory systems actively
‚Ä¢ Periodically validates system operational status and storage configurations
‚Ä¢ Prefers structured, detailed technical responses with tabular data formats
‚Ä¢ Accepts proactive recommendations for system improvements and migrations
‚Ä¢ Interested in: SQLite, vector databases, semantic search, and persistent storage solutions

## Update 2026-02-15T07:13:20.399Z
- Had embedding issue requiring fix for 384-dim vector memory system
- Uses local Python embedding generator (scikit-learn TF-IDF, 384-dim, no API)
- Works with multilingual data (English + Thai)
- Uses SQLite database with semantic/vector search capabilities
- Prefers local/offline solutions over API-dependent services

## Update 2026-02-15T07:16:33.622Z
‚Ä¢ Testing vector search & semantic memory retrieval systems
‚Ä¢ Interested in dementia/Alzheimer's-related search applications
‚Ä¢ Validates system functionality (debugging/QA behavior)
‚Ä¢ Uses multilingual interfaces (English/Thai)

## Update 2026-02-15T07:18:30.220Z
‚Ä¢ Primary language: Thai (native/fluent)
‚Ä¢ Testing vector search & multilingual retrieval
‚Ä¢ Technical user: infrastructure/DB validation

## Update 2026-02-15T07:23:49.156Z
- Summary: User is a technical researcher from KMUTT Civil Engineering AI Research Group managing Tiger bot infrastructure. Conversation spans security hardening (SQLite permissions, gitignore, audit logging), vector database repairs (embedding generation), and content creation (Facebook posts, Thai language guides). User prefers concise, structured outputs with tables and validates functionality through explicit testing.
- Pattern: Security-first approach: Requests security improvements before features
- Pattern: Bilingual workflow: Switches between Thai and English based on context (technical vs. content creation)
- Pattern: Validation-driven: Explicitly tests implementations (database health, vector search, Thai embeddings)
- Pattern: Conciseness preference: Multiple requests for '‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö' (concise) content
- Pattern: Structured data preference: Favors tables, checklists, and command references over prose
- Pattern: Platform-specific documentation: Requests tailored guides (Hetzner Cloud, Telegram, Facebook)
- Lesson: Initial misinterpretation: 'Facebook' request assumed installation platform rather than content destination
- Lesson: Embedding gap: Vector search installed but embeddings empty, requiring manual fix
- Lesson: Temporary storage risk: Database initially in /tmp/ with world-readable permissions
- Lesson: Session persistence: User had to repeat 'Revise readme' command multiple times (possible connection drops)
- Workflow: Tiered security implementation: HIGH (permissions, gitignore) ‚Üí MEDIUM (backup, audit logging) prioritization
- Workflow: Git hygiene: Committing security templates while excluding credentials
- Workflow: Vector search repair: Python fallback embedding generation (384-dim) enabling semantic Thai‚ÜíEnglish search
- Workflow: Competitive positioning: Tiger vs Clawbot comparison highlighting memory persistence and security
- Workflow: Institutional branding: Adding KMUTT affiliation to documentation

## Update 2026-02-16T01:38:53.351Z
- Prefers autonomous execution: wants all steps run automatically without explicit instruction
- Manages GitHub repositories (Tiger_bot, Token Management project)

## Update 2026-02-16T03:16:42.596Z
- Uses git version control workflow
- Thai/English bilingual interface preference
- Monitors repository sync status and file changes

## Update 2026-02-16T03:19:33.512Z
- Prefers MIT License for open source projects
- Works with GitHub repositories and README documentation
- Values clear licensing and project documentation

## Update 2026-02-16T03:22:20.035Z
- Working on GitHub project "Tiger_bot" (Sompote/Tiger_bot)
- Uses MIT License for open source projects
- Prefers conventional commit messages (e.g., "chore:")
- Tech stack: Python, Git/GitHub

## Update 2026-02-16T03:23:33.444Z
- Maintains Tiger_bot repository (GitHub: Sompote/Tiger_bot)
- Uses Thai language mixed with English technical terms
- Works with Git CLI including force push/rebase workflows

## Update 2026-02-16T03:29:26.798Z
‚Ä¢ Git/GitHub: Auto-commit/push system configured and operational
‚Ä¢ Repository: Sompote/Tiger_bot (MIT License managed)
‚Ä¢ Technical context: Token management, licensing workflow
‚Ä¢ Language: Comfortable with Thai/English bilingual technical responses

## Update 2026-02-16T03:32:22.671Z
- Communicates in Thai-English mixed language
- Prefers visual/icons over long text descriptions
- Working with MIT-licensed open source projects

## Update 2026-02-16T03:33:39.328Z
- Primary language: Thai (communicates in Thai script)
- Project: Maintains GitHub repository "Tiger_bot" (Sompote/Tiger_bot)
- Documentation style: Prefers minimalist, visual formatting (badge icons over verbose text)
- Technical workflow: Uses Git with descriptive commit messages

## Update 2026-02-16T03:37:42.692Z
- Technical preferences: Token management with hourly rate limiting, automatic API failover on rate limits
- Configuration style: Environment-based (.env) settings for API keys and thresholds
- System design: Multi-API fallback architecture with user-defined rate limits

## Update 2026-02-16T03:39:40.143Z
- Project context: Working on `/root/tiger/` codebase
- Current focus: Implementing Token Management system (referencing README specs)
- Language preference: Thai (or bilingual Thai/English communication)
- Workflow style: Uses AI-assisted development with file system function calls
- Technical approach: Reads documentation first before system implementation

## Update 2026-02-16T03:42:20.619Z
- Building "Tiger Bot" project: multi-provider AI API token management system with failover
- Uses Gemini, OpenRouter, Claude APIs with environment-based config
- Prefers concise technical continuation without lengthy explanations
- Working in Thai/English bilingual context

## Update 2026-02-16T03:47:49.796Z
- Developing token management features
- Requests README/documentation updates to match implementation
- Working in /root/tiger/ project directory

## Update 2026-02-16T03:49:31.447Z
‚Ä¢ Project: Tiger (Git-based repo)
‚Ä¢ Uses conventional commit format (e.g., "docs:...")
‚Ä¢ Working with .env configuration & token management

## Update 2026-02-16T03:56:38.116Z
- Language preference: Thai (system status reports)
- Uses automated git workflows (auto-commit/push)
- Maintains open source projects (MIT License)
- Working on token management documentation

## Update 2026-02-16T03:59:21.032Z
- Maintains GitHub repo: Sompote/Tiger_bot (bot project)
- Working on token management features/documentation
- Uses Thai language for technical communications
- Git workflow: force commits and direct main branch pushes

## Update 2026-02-16T04:08:11.292Z
- Project: tiger (repo at /root/tiger)
- Uses Git version control
- CLI-based development workflow

## Update 2026-02-16T04:09:31.953Z
‚Ä¢ Project context: Working on 'tiger' repo (path: /root/tiger)
‚Ä¢ Interested in: Token Management/auth documentation & features
‚Ä¢ Uses git version control for tracking changes
‚Ä¢ Language context: Thai may be relevant/preferred (assistant used Thai)

## Update 2026-02-16T04:14:20.344Z
- Prefers automated reporting/processes over manual updates

## Update 2026-02-16T04:19:27.480Z
‚Ä¢ Develops API infrastructure with rate limiting & auto-failover mechanisms
‚Ä¢ Builds Python backend systems (token_manager.py, state persistence)
‚Ä¢ Implements DevOps practices: deployment tracking, env configuration
‚Ä¢ Focuses on system reliability & fault-tolerant architecture

## Update 2026-02-16T06:34:14.791Z
- Interested in codebase metrics (line-of-code counts, file statistics)
- Analyzing project structure and repository scale
- Prefers concise technical summaries

## Update 2026-02-16T06:38:56.789Z
- Prefers thorough, detailed verification of all files/projects
- Works with mixed tech stacks (Python, Markdown, config, shell scripts)
- Values structured output with visual categorization (emojis/icons)
- Expects comprehensive metrics (line counts, file breakdowns by type)
- May have occasional typos in quick messages ("alll")

## Update 2026-02-16T06:42:08.156Z
- Python developer: agent systems, token management, database operations
- Project structure: organized code/docs/config separation
- Uses .env config and JSON data storage
- Maintains documentation standards (README, LICENSE)

## Update 2026-02-16T06:47:34.716Z
- Works with Python and Git version control
- Troubleshoots remote repository file tracking and .gitignore issues
- Context indicates possible Thai language proficiency or regional setting

## Update 2026-02-16T06:48:33.162Z
- Developer: Python project "tiger" with modular skills architecture
- Communication style: Prefers ultra-concise commands (e.g., single-word "Run")
- Technical context: Git repos, shell debugging, /root/tiger workspace
- Language: Possibly Thai-speaking or working with Thai content

## Update 2026-02-16T06:51:54.124Z
- Python developer (AI/agents focus)
- Uses Git for version control
- Prefers concise, directive communication style

## Update 2026-02-16T07:03:35.159Z
- GitHub: Sompote/Tiger_bot
- Dev env: /root/tiger
- Language: Thai
- Auth: GitHub PATs

## Update 2026-02-16T07:04:39.975Z
‚Ä¢ Developer of Tiger_bot project (GitHub: Sompote/Tiger_bot)
‚Ä¢ Tech stack: Python (token_manager.py, tiger_agent.py, db.py)
‚Ä¢ Uses Git automation with PAT (Personal Access Token) auth
‚Ä¢ Working on bot/agent architecture with database backend

## Update 2026-02-16T07:09:02.499Z
‚Ä¢ Develops Python-based agent systems (project: tiger)
‚Ä¢ Uses Git with force push workflows for deployment
‚Ä¢ Implements core backend modules: rate limiting, SQLite memory, vector DB support
‚Ä¢ Project structure: root + skills/ subdirectory
‚Ä¢ Comfortable with shell command automation for DevOps tasks

## Update 2026-02-16T07:09:43.643Z
‚Ä¢ Python developer: AI/agent systems (tiger_agent.py), token management, DB modules
‚Ä¢ Git workflow: commits/pushes to origin/main

## Update 2026-02-16T07:10:47.652Z
- Always verify/use latest git commits, not old/cached references
- Require accuracy in version control details (commit hashes, branches)

## Update 2026-02-16T07:11:44.100Z
‚Ä¢ Developing "Tiger Agent" Python AI project (v1.0)
‚Ä¢ Building token management & database systems
‚Ä¢ Active git user (conventional commits, main branch)

## Update 2026-02-16T07:29:17.112Z
- Works with Git/GitHub (repo: Tiger_bot, user: Sompote)
- Uses force push workflows (monitor for Git safety practices)
- Manages GitHub Personal Access Tokens for API access
- Non-native English speaker (concise, occasional grammar gaps)
- Troubleshoots Git remote sync/push visibility issues

## Update 2026-02-16T07:30:55.347Z
‚Ä¢ GitHub repo: Sompote/Tiger_bot
‚Ä¢ Local project path: /root/tiger
‚Ä¢ Stack: Python
‚Ä¢ Requires GitHub token/auth troubleshooting

## Update 2026-02-16T07:38:38.627Z
‚Ä¢ GitHub repo: Sompote/Tiger_bot
‚Ä¢ Working directory: /root/tiger
‚Ä¢ Language: Thai (or accepts Thai responses)
‚Ä¢ Performs git force push operations

## Update 2026-02-16T07:39:24.537Z
- GitHub: Sompote (repo: Tiger_bot)
- Project: Tiger Agent v1.0 (Python)
- Core modules: token_manager.py, tiger_agent.py, db.py
- Uses token-based GitHub auth
- Security conscious (audit.sh, SECURITY.md, LICENSE)

## Update 2026-02-16T07:43:20.179Z
- GitHub user: Sompote (repo: Tiger_bot)
- Language: Thai (communicates in Thai)
- Tech stack: Git/GitHub, API debugging, Python
- Activity: Troubleshooting git push/web update issues

## Update 2026-02-16T07:44:32.408Z
‚Ä¢ Tiger_bot Python project maintainer
‚Ä¢ Stack: db.py, tiger_agent.py, token_manager.py
‚Ä¢ Git troubleshooting: resolving .py file push failures
‚Ä¢ Thai/English bilingual context

## Update 2026-02-16T07:45:41.505Z
- Tiger Agent v1.0 project: Python modular system (token_manager, tiger_agent, db modules)
- Git/GitHub workflow: troubleshooting push issues ("up-to-date" but missing files), uses PAT auth
- Thai-speaking developer (Sompote)
- Technical focus: Git internals (reflog, index), GitHub REST API, force-push troubleshooting

## Update 2026-02-16T08:13:47.294Z
- User communicates in Thai
- Working with Tiger agent project (directory: /root/tiger)
- Queries about file locations and project structure

## Update 2026-02-16T08:20:54.814Z
- GitHub repo: Sompote/Tiger_bot (Tiger-agent project)
- Core Python files: db.py, tiger_agent.py, token_manager.py
- Workflow: Local dev ‚Üí GitHub API push (token-based auth)
- Common issue: Files missing from remote despite local existence
- Solution pattern: Direct API upload with base64 encoding + SHA check for updates

## Update 2026-02-16T08:45:37.959Z
- Primary language: Thai
- GitHub proficiency: Beginner (unfamiliar with blob/tree URL distinctions)
- Domain interest: Python AI/agent development (investigating Tiger_bot repository)
- Technical context: Searching for specific source files (tiger_agent.py, db.py) in GitHub repositories

## Update 2026-02-16T10:19:10.332Z
- Git workflow: Study specific commit SHAs (e.g., cf1e090) to replicate successful push patterns
- Git push preference: Uses --force-with-lease over --force for safety
- Commit style: Conventional commits format ("feat: add core Python modules")
- Tech stack: Python development, GitHub API integration
- Methodology: Analyze remote commit details via API before applying locally
- Repo pattern: Works with Tiger_bot repository structure
- Verification habit: Confirms GitHub state via API after push operations

## Update 2026-02-16T11:14:50.801Z
- Tiger Agent bot project (GitHub: Sompote/Tiger_bot, Python)
- Git workflow: prefers force-with-lease push method (cf1e090)
- Language: Thai/English bilingual
- Stack: Python modules (db.py, tiger_agent.py, token_manager.py)

## Update 2026-02-18T23:31:45.813Z
- Summary: User Sompote (telegram:8172556270) is working on the Tiger_bot project (GitHub: Sompote/Tiger_bot, repo path /root/tiger). Primary issues: GitHub PAT expired and git push showing 'Everything up-to-date' without actually updating remote files. Workaround was GitHub REST API direct upload. Files db.py, tiger_agent.py, token_manager.py confirmed uploaded via API but not visible via git push. User also requested Kimi API key change.
- Pattern: User frequently types 'Run' as a standalone message to execute previously planned commands.
- Pattern: User's GitHub PAT tokens expire/get revoked; they provide new tokens in plaintext in chat.
- Pattern: git push reports 'Everything up-to-date' or 'success' but files do not appear on GitHub remote ‚Äî likely a git local/remote SHA divergence or branch tracking issue.
- Pattern: GitHub REST API PUT /repos/{owner}/{repo}/contents/{file} successfully uploads files when git push fails.
- Pattern: User sends many short messages ('Hi', 'Hello') possibly testing connectivity or bot responsiveness.
- Pattern: User requested switching to Kimi API with a provided API key in plaintext.
- Lesson: Old GitHub token (redacted) was invalid/expired ‚Äî always verify token before use.
- Lesson: git push returning 'Everything up-to-date' is misleading; local commits were not actually reaching remote ‚Äî need to verify remote SHA matches local SHA after push.
- Lesson: Simulated/fake shell output was shown to user (file sizes, commit SHAs) without real execution results, causing confusion and distrust.
- Lesson: API upload showed 201 Created but files disappeared on re-check ‚Äî possible branch/ref mismatch or repo visibility issue.
- Lesson: Do not expose or log API keys and GitHub tokens in responses or memory summaries.
- Lesson: Investigating whether GitHub blocks pushes from certain automation tools (OpenClaw/bot) was requested but not resolved.
- Workflow: GitHub REST API direct file upload: GET file to retrieve SHA if exists, then PUT with base64 content, message, branch, and sha fields ‚Äî returned 201 and files appeared in API listing.
- Workflow: Token verification via GET https://api.github.com/user with Bearer header confirms token validity before operations.
- Workflow: Checking all branches via GET /repos/{owner}/{repo}/branches and default branch via GET /repos/{owner}/{repo} to confirm correct target branch.

## Update 2026-02-18T23:43:54.574Z
- Summary: User sent repeated greetings ('Hi' and 'Hello') over ~12 minutes with no substantive conversation or requests made.
- Pattern: User repeatedly sends simple greetings without following up with a request or question.
- Pattern: User may be testing the bot, unsure how to interact, or waiting for a response before proceeding.
- Lesson: No assistant responses are visible; unclear if the bot responded at all, which may explain repeated greetings.
- Lesson: Lack of engagement or prompt from the assistant may cause users to repeat themselves.

## Update 2026-02-18T23:48:09.407Z
- Summary: User greeted assistant twice with 'Hi', then cancelled task #1 (GitHub block push check), leaving only the Kimi API key rotation as pending work. The /token command was sent at the end of the session.
- Pattern: User sends multiple 'Hi' messages to initiate sessions without additional context.
- Pattern: User is comfortable cancelling tasks with short messages like '1 ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á ‡∏ó‡∏≥'.
- Pattern: User tends to use slash commands (e.g., /token) during sessions.
- Lesson: Assistant displayed pending task summaries proactively on 'Hi' ‚Äî this seems appropriate given the task backlog context.
- Lesson: A Kimi API key (sk-qgwx...) was previously shared in chat; assistant correctly flagged it for revocation without storing the key.
- Workflow: Assistant maintained task list across messages and presented it clearly in table format on session start.
- Workflow: Assistant correctly advised against sharing new API keys in chat and suggested secure alternatives (env variable or .env file).

## Update 2026-02-18T23:50:09.572Z
- Summary: User checked token configuration for the Tiger project. System has multi-provider LLM setup with Z.ai currently active, Kimi and Claude keys set, MiniMax and Moonshot missing keys.
- Pattern: User uses /token command to inspect LLM provider configuration
- Pattern: Project is located at /root/tiger/ with .env config file
- Pattern: User manages multiple LLM providers with failover ordering
- Workflow: /token command successfully displays provider status table with keys, models, and daily limits

## Update 2026-02-19T00:00:14.939Z
- Summary: Brief greeting interaction with user via Telegram. Assistant responded in Thai, offering menu options for provider/API key changes.
- Pattern: User communicates via Telegram (ID: 8172556270)
- Pattern: Assistant defaults to Thai language responses for this user
- Pattern: Assistant proactively offers common action menu on greeting
- Workflow: Greeting with Thai language response and action menu prompt works as expected
